# RÃ©gression multiple & neurone artificiel
Ce mini-projet pÃ©dagogique montre comment passer d'une rÃ©gression linÃ©aire multiple Ã  un neurone artificiel, Ã  l'aide d'un exemple simple basÃ© sur les performances d'Ã©tudiants.

ğŸ¯ Objectif

PrÃ©dire le score dâ€™un Ã©tudiant (Ã©tudiant D) en fonction de deux paramÃ¨tres :
â³ Temps dâ€™Ã©tude

ğŸ˜´ Temps de sommeil

| Ã‰tudiant | Temps d'Ã©tude (x1) | Temps de sommeil (x2) | Score (y) |
| -------- | ------------------ | --------------------- | --------- |
| A        | 2                  | 6                     | 0.3       |
| B        | 3                  | 7                     | 0.5       |
| C        | 1                  | 8                     | 0.4       |
| D        | 4                  | 5                     | ?         |

ğŸ§® RÃ©gression linÃ©aire multiple
On cherche une relation linÃ©aire entre les variables d'entrÃ©e et le score :
y= a1â‹…x1 + a2â‹…x2 + b

x1 : temps d'Ã©tude
x2 : temps de sommeil
y : score
a1, a2 : poids appris
b : biais (interception)
##ğŸ“ MÃ©thode : rÃ©solution par les moindres carrÃ©s
On utilise une formule matricielle pour rÃ©soudre ce systÃ¨me de maniÃ¨re rapide et fiable (utilisÃ©e aussi en Python) :
Î¸=(X^TX) âˆ’1X^Ty

â• Construction des matrices
Matrice X (avec biais ajoutÃ© sous forme de 1) :

A COMPLETER
â€‹
â€‹
  
â€‹

  
â€‹
 

âœ… RÃ©sultat du calcul matriciel (ou avec NumPy) :
theta_best = np.linalg.inv(X.T @ X) @ X.T @ y
Donne :
a1 = 0.1
a2 = 0.1
b = -0.5
##ğŸ” PrÃ©diction pour l'Ã©tudiant D
Ã‰tudiant D a :

4 heures dâ€™Ã©tude
5 heures de sommeil

ğ‘¦ğ·=0.1â‹… 4+0.1â‹…5âˆ’0.5=0.4y D
=0.1â‹…4+0.1â‹…5âˆ’0.5=0.4

#ğŸ§  Passage au neurone artificiel
On considÃ¨re maintenant que ce modÃ¨le est un neurone simple :
z=a1â‹…x1 + a2â‹…x2 + b
â€‹Puis on applique une fonction d'activation pour obtenir une probabilitÃ© :
âœ… Fonction sigmoÃ¯de :
Ïƒ(z)=1/1+e^âˆ’z
Application pour z = 0.4 :
ğœ(0.4)â‰ˆ0.5987

ğŸ‘‰ Ce rÃ©sultat peut Ãªtre interprÃ©tÃ© comme une probabilitÃ© de rÃ©ussite de 59.87% pour lâ€™Ã©tudiant D.
--------------------------------------------------------------------------------------------------------------------
ğŸ“Œ Conclusion
âœ… La rÃ©gression multiple apprend les poids optimaux pour combiner plusieurs variables.
âœ… En ajoutant une fonction dâ€™activation, on transforme la sortie en probabilitÃ© â†’ câ€™est un neurone artificiel !
ğŸ§  Câ€™est la base du machine learning et des rÃ©seaux de neurones.

--------------------------------------------------------------------------------------------------------------------

##ğŸ’¬ Et vous ?
Quelles autres variables pourraient influencer la rÃ©ussite dâ€™un Ã©tudiant ? ğŸ’­
Stress, alimentation, motivation ? Faites vos suggestions !
