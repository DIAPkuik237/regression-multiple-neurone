# ğŸ“˜ RÃ©gression multiple & neurone artificiel

Ce mini-projet pÃ©dagogique montre comment passer d'une **rÃ©gression linÃ©aire multiple** Ã  un **neurone artificiel**, Ã  l'aide d'un exemple simple basÃ© sur les performances d'Ã©tudiants.

---

## ğŸ¯ Objectif

PrÃ©dire le score dâ€™un Ã©tudiant (Ã©tudiant D) en fonction de deux paramÃ¨tres :

- â³ Temps dâ€™Ã©tude (`x1 = 4`)
- ğŸ˜´ Temps de sommeil (`x2 = 5`)

---

## ğŸ“Š DonnÃ©es

| Ã‰tudiant | Temps d'Ã©tude (x1) | Temps de sommeil (x2) | Score (y) |
|----------|--------------------|------------------------|-----------|
| A        | 2                  | 6                      | 0.3       |
| B        | 3                  | 7                      | 0.5       |
| C        | 1                  | 8                      | 0.4       |
| D        | 4                  | 5                      | ?         |

> ğŸ” On ajoute une colonne de `1` dans la matrice des donnÃ©es pour intÃ©grer le **biais** `b`.

---

## ğŸ§® RÃ©gression linÃ©aire multiple

On cherche une relation du type :
y = a1 * x1 + a2 * x2 + b

Avec :

- `x1` : temps d'Ã©tude  
- `x2` : temps de sommeil  
- `a1`, `a2` : poids appris pour chaque variable  
- `b` : biais (interception)

---

## ğŸ“ MÃ©thode des moindres carrÃ©s

### Forme matricielle

Formule utilisÃ©e :
theta = (Xáµ— * X)^(-1) * Xáµ— * y


























